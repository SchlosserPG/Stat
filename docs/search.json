[
  {
    "objectID": "introR.html",
    "href": "introR.html",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "At a Glance",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#what-is-statistics",
    "href": "introR.html#what-is-statistics",
    "title": "Introduction to R and RStudio",
    "section": "What is Statistics?",
    "text": "What is Statistics?\n\nStatistics is the methodology of extracting useful information from a data set.\nNumerical results are not very useful unless they are accompanied with clearly stated actionable business insights.\nTo do good statistical analysis, you must do the following:\n\nFind the right data.\nUse the appropriate statistical tools.\nClearly communicate the numerical information in written language.\n\nWith knowledge of statistics:\n\nAvoid risk of making uninformed decisions and costly mistakes.\nDifferentiate between sound statistical conclusions and questionable conclusions.\n\nData and analytics capabilities have made a leap forward.\n\nGrowing availability of vast amounts of data.\nImproved computational power.\nDevelopment of sophisticated algorithms.\nThe rise of Generative AI.\n\n\n\nTwo Main Branches of Statistics\n\nDescriptive Statistics - collecting, organizing, and presenting the data.\nInferential Statistics - drawing conclusions about a population based on sample data from that population.\n\nA population consists of all items of interest.\nA sample is a subset of the population.\nA sample statistic is calculated from the sample data and is used to make inferences about the population parameter.\n\nReasons for sampling from the population:\n\nToo expensive to gather information on the entire population.\nOften impossible to gather information on the entire population.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#setting-up-r",
    "href": "introR.html#setting-up-r",
    "title": "Introduction to R and RStudio",
    "section": "Setting up R",
    "text": "Setting up R",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#r-script-files",
    "href": "introR.html#r-script-files",
    "title": "Introduction to R and RStudio",
    "section": "R Script Files",
    "text": "R Script Files\n\nUsing R Script Files:\n\nA .R script is simply a text file containing a set of commands and comments. The script can be saved and used later to rerun the code. The script can also be documented with comments and edited again and again to suit your needs.\n\nUsing the Console\n\nEntering and running code at the R command line is effective and simple. However, each time you want to execute a set of commands, you must re-enter them at the command line. Nothing saves for later.\n\nComplex commands are particularly difficult causing you to re-entering the code to fix any errors typographical or otherwise.R script files help to solve this issue.\n\n\nCreate a New R Script File\n\nTo save your notes from today’s lecture, create a .R file named Chapter1.R and save it to your project file you made in the last class.\nThere are a couple of parts to this chapter, and we can add code from today’s chapter in one file so that our code is stacked nicely together.\n\nFor each new chapter, start a new file and save it to your project folder.\n\n\n\n\nScreenshot of R Environment",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#text-in-r",
    "href": "introR.html#text-in-r",
    "title": "Introduction to R and RStudio",
    "section": "Text in R",
    "text": "Text in R\n\nComments\n\nUse comments to organize and explain your code in R scripts by including 1 or more than 1 hashtag.\nAim to write clear, self-explanatory code that minimizes the need for excessive comments.\nAdd helpful comments where necessary to ensure anyone, including your future self, can understand and run the code.\nIf something doesn’t work, avoid deleting it immediately. Instead, comment it out while troubleshooting or exploring alternatives.\nEssentially, we add comments to our code to document our work and add notes to our self or to others.\n\n\n# This is a comment for documentation or annotation\n\n\nAdd the code above to your R file and run each line using Ctl + Enter (PC) or Cmd + Return (MAC) or select all lines and click Run.\nTake note that nothing prints in the console after running a comment.\n\n\n\nA Prolog\n\nA prolog is a set of comments at the top of a code file that provides information about what is in the file. It also names the files and resources used that facilitates identification. Including a prolog is considered coding best practice.\nOn your own R Script File, add your own prolog following the template as shown.\nAn informal prolog is below:\n\n\n####################################\n# Project name: Chapter 1\n# Project purpose: To create an R script file to learn about R. \n# Code author name: [Enter Your Name]\n# Date last edited: [Enter Date Here]\n# Data used: NA\n# Libraries used: NA\n####################################\n\n\nThen, as we work through our .R script and add data files or libraries to our code, we go back and edit the prolog.\n\n\n\n\nChapter 1 R File\n\n\n\n\nString\n\nIn R, a string is a sequence of characters enclosed in quotes, used to represent text data.\nR accepts single quotes or double quotes when marking a string. However, if you use a single quote to start, use a single quote to end. The same for double quotes - ensure the pairing is the same quote type.\nYou sometimes need to be careful with nested quotes, but generally it does not matter which you use.\n\n\n\"This is a string\"\n\n[1] \"This is a string\"\n\n\"This is also a string\"\n\n[1] \"This is also a string\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#note-on-r-markdown",
    "href": "introR.html#note-on-r-markdown",
    "title": "Introduction to R and RStudio",
    "section": "Note on R Markdown",
    "text": "Note on R Markdown\n\nThese files were formatted with RMarkdown. RMarkdown is a simple formatting syntax for authoring documents of a variety of types, including PowerPoint and html files.\nOn the document, RMarkdown prints the command and then follows the command with the output after 2 hashtags.\nIn your R Script File, you only need to type in the command and then run your code to get the same output as presented here.\n\n\n\n\nReading our HTML file",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#running-commands",
    "href": "introR.html#running-commands",
    "title": "Introduction to R and RStudio",
    "section": "Running Commands",
    "text": "Running Commands\n\nThere are a few ways to run commands via your .R file.\n\nYou can click Ctr + Enter on each line (Cmd + Return on a Mac).\nYou can select all the lines you want to run and select Ctr + Enter (Cmd + Return on a Mac).\nYou can select all the lines you want to run and select the run button as shown in the Figure.\n\n\n\n\n\nRun Code\n\n\n\nNow that I have asked you to add a couple lines of code, after this point, when R code is shown on this file, you should add it to your .R script file along with any notes you want. I won’t explicitly say - “add this code.”",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#r-is-an-interactive-calculator",
    "href": "introR.html#r-is-an-interactive-calculator",
    "title": "Introduction to R and RStudio",
    "section": "R is an Interactive Calculator",
    "text": "R is an Interactive Calculator\n\nAn important facet of R is that it should serve as your sole calculator.\nTry these commands in your .R file by typing them in and clicking Ctr + Enter on each line.\n\n\n3 + 4\n\n[1] 7\n\n3 * 4\n\n[1] 12\n\n3/4\n\n[1] 0.75\n\n3 + 4 * 100^2\n\n[1] 40003\n\n\n\nTake note that order of operations holds in R: PEMDAS\n\nParentheses ()\nExponents ^ and \\(**\\)\nDivision \\(/\\), Multiplication \\(*\\), modulo, and integer division\nAddition + and Subtraction -\n\nNote that modulo and integer division have the same priority level as multiplication and division, where modulo is just the remainder.\n\n\nprint(2 + 3 * 5 - 7^2%%4 + (5/2))\n\n[1] 18.5\n\n5/2  #parentheses: = 2.5\n\n[1] 2.5\n\n7^2  #exponent:= 49\n\n[1] 49\n\n3 * 5  #multiplication: = 15\n\n[1] 15\n\n17%%4  #modulo: = 1\n\n[1] 1\n\n17%/%4  #integer division: = 4\n\n[1] 4\n\n2 + 15  #addition: = 17\n\n[1] 17\n\n17 - 1  #subtraction: = 16\n\n[1] 16\n\n16 + 2.5  #addition: = 18.5\n\n[1] 18.5",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#observations-and-variables",
    "href": "introR.html#observations-and-variables",
    "title": "Introduction to R and RStudio",
    "section": "Observations and Variables",
    "text": "Observations and Variables\n\nGoing back to the basics in statistics, we need to define an observation and variable so that we can know how to use them effectively in R in creating objects.\nAn Observation is a single row of data in a data frame that usually represents one person or other entity.\nA Variable is a measured characteristic of some entity (e.g., income, years of education, sex, height, blood pressure, smoking status, etc.).\nIn data frames in R, the columns are variables that contain information about the observations (rows).\n\nNote that we will break this code down later.\n\n\nincome &lt;- c(34000, 123000, 215000)\nvoted &lt;- c(\"yes\", \"no\", \"no\")\nvote &lt;- data.frame(income, voted)\nvote\n\n  income voted\n1  34000   yes\n2 123000    no\n3 215000    no\n\n\nObservations: People being measured.\nVariables: Information about each person (income and voted).\n\n\n# Shows the number of columns or variables\nncol(vote)\n\n[1] 2\n\n# Shows the number of rows or observations\nnrow(vote)\n\n[1] 3\n\n# Shows both the number of rows (observations and columns\n# (variables).\ndim(vote)\n\n[1] 3 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#creating-objects",
    "href": "introR.html#creating-objects",
    "title": "Introduction to R and RStudio",
    "section": "Creating Objects",
    "text": "Creating Objects\n\nEntering and Storing Variables in R requires you to make an assignment.\n\nWe use the assignment operator ‘&lt;-’ to assign a value or expression to a variable.\nWe typically do not use the = sign in R even though it works because it also means other things in R.\n\nSome examples are below to add to your .R file.\n\n\nstates &lt;- 29\nA &lt;- \"Apple\"\n# Equivalent statement to above - again = is less used in R.\nA = \"Apple\"\nprint(A)\n\n[1] \"Apple\"\n\n# Equivalent statement to above\nA\n\n[1] \"Apple\"\n\nB &lt;- 3 + 4 * 12\nB\n\n[1] 51\n\n\n\n\n\nThe Assignment Operator\n\n\n\nNaming Objects\n\nLine length limit: 80\nAlways use a consistent way of annotating code.\nCamel case is capitalizing the first letter of each word in the object name, with the exception of the first word.\nDot case puts a dot between words in a variable name while camel case capitalizes each word in the variable name.\nObject names appear on the left of assignment operator. We say an object receives or is assigned the value of the expression on the right.\n\n\nNaming Constants: A Constant contains a single numeric value.\n\n\nThe recommended format for constants is starting with a “k” and then using camel case. (e.g., kStates).\n\n\nNaming Functions: Functions are objects that perform a series of R commands to do something in particular.\n\n\nThe recommended format for Functions is to use Camel case with the first letter capitalized. (e.g., MultiplyByTwo).\n\n\nNaming Variables: A Variable is a measured characteristic of some entity.\n\n\nThe recommended format for variables is to use either the dot case or camel case. e.g., filled.script.month or filledScriptMonth.\nA valid variable name consists of letters, numbers, along with the dot or underline characters.\nA variable name must start with a letter, or the dot when not followed by a number.\nA variable cannot contain spaces.\nVariable names are case sensitive: x is different from X just as Age is different from AGE.\nThe value on the right must be a number, string, an expression, or another variable.\nSome Examples Using Variable Rules:\n\n\nAB.1 &lt;- \"Allowed?\"\n# Does not follow rules - not allowed Try the statement below with no\n# hashtag to see the error message .123 &lt;- 'Allowed?'\nA.A123 &lt;- \"Allowed?\"\nG123AB &lt;- \"Allowed?\"\n# Recommended format for constants\nkStates &lt;- 29\n\n\nDifferent R coders have different preferences, but consistency is key in making sure your code is easy to follow and for others to read. In this course, we will generally use the recommendation in the text which are listed above.\nWe tend to use one letter variable names (i.e., x) for placeholders or for simple functions (like naming a vector).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#built-in-functions",
    "href": "introR.html#built-in-functions",
    "title": "Introduction to R and RStudio",
    "section": "Built-in Functions",
    "text": "Built-in Functions\n\nR has thousands of built-in functions including those for summary statistics. Below, we use a few built-in functions with constant numbers. The sqrt(), max(), and min() functions compute the square root of a number, and find the maximum and minimum numbers in a vector.\n\n\nsqrt(100)\n\n[1] 10\n\nmax(100, 200, 300)\n\n[1] 300\n\nmin(100, 200, 300)\n\n[1] 100\n\n\n\nWe can also create variables to use within built-in functions.\nBelow, we create a vector x and use a few built-in functions as examples.\n\nThe sort() function sorts a vector from small to large.\n\n\nx &lt;- c(1, 2, 3, 3, 100, -10, 40)  #Creating a Vector x\nsort(x)  #Sorting the Vector x from Small to Large\n\n[1] -10   1   2   3   3  40 100\n\nmax(x)  #Finding Largest Element of Vector x\n\n[1] 100\n\nmin(x)  #Finding Smallest Element of Vector x\n\n[1] -10\n\n\n\n\nBuilt-in Functions: Setting an Argument\n\nThe standard format to a built-in function is functionName(argument)\n\nFor example, the square root function structure is listed as sqrt(x), where x is a numeric or complex vector or array.\n\n\n\n# Here, we are setting a required argument x to a value of 100. When\n# a value is set, it turns it to a parameter of the function.\nsqrt(x = 100)\n\n[1] 10\n\n# Because there is only one argument and it is required, we can\n# eliminate its name x= from our function call. This is discussed\n# below.\nsqrt(100)\n\n[1] 10\n\n\n\nThere is a little variety in how we can write functions to get the same results.\nA parameter is what a function can take as input. It is a placeholder and hence does not have a concrete value. An argument is a value passed during function invocation.\nThere are some default values set up in R in which arguments have already been set.\nThere are a few functions with no parameters like Sys.time() which produces the date and time. If you are not sure how many parameters a function has, you should look it up in the help.\n\n\n\nDefault Values\n\nThere are many default values set up in R in which arguments have already been set to a particular value or field.\nDefault values have been set when you see the = value in the instructions. If we don’t want to change it, we don’t need to include it in our function call.\nWhen only one argument is required, the argument is usually not set to have a default value.\n\n\n\nBuilt-in Functions: Using More than One Argument\n\nFor functions with more than one parameter, we must determine what arguments we want to include, and whether a default value was set and if we want to change it. Default values have been set when you see the = value in the instructions. If we don’t want to change it, we don’t need to include it in our function call.\n\nFor example, the default S3 method for the seq() function is listed as the following: seq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),length.out = NULL, along.with = NULL, …)\nDefault values have been set on each parameter, but we can change some of them to get a meaningful result.\nFor example, we set the from, to, and by parameter to get a sequence from 0 to 30 in increments of 5.\n\n\n\n# We can use the following code.\nseq(from = 0, to = 30, by = 5)\n\n[1]  0  5 10 15 20 25 30\n\n\n\nWe can simplify this function call even further:\n\nIf we use the same order of parameters as the instructions, we can eliminate the argument= from the function.\nSince we do list the values to the arguments in same order as the function is defined, we can eliminate the from=, to=, and by= to simplify the statement.\n\n\n# Equivalent statement as above\nseq(0, 30, 5)\n\n[1]  0  5 10 15 20 25 30\n\n\nIf you leave off the by parameter, it defaults at 1.\n\n\n# Leaving by= to default value of 1\nseq(0, 30)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n[26] 25 26 27 28 29 30\n\n\n\nThere can be a little hurdle deciding when you need the argument value in the function call. The general rule is that if you don’t know, include it. If it makes more sense to you to include it, include it.\n\n\n\nTips on Arguments\n\nAlways look up a built-in function to see the arguments you can use.\nArguments are always named when you define a function.\nWhen you call a function, you do not have to specify the name of the argument.\nArguments have default values, which is used if you do not specify a value for that argument yourself.\nAn argument list comprises of comma-separated values that contain the various formal arguments.\nDefault arguments are specified as follows: parameter = expression\n\n\ny &lt;- 10:20\nsort(y)\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\nsort(y, decreasing = FALSE)\n\n [1] 10 11 12 13 14 15 16 17 18 19 20",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#saving",
    "href": "introR.html#saving",
    "title": "Introduction to R and RStudio",
    "section": "Saving",
    "text": "Saving\n\nYou can save your work in the file menu or the save shortcut using Ctrl + S or Cmd+S depending on your Operating System.\nYou will routinely be asked to save your workspace image, and you don’t need to save this unless specifically asked. It saves the output we have generated so far.\nYou can stop this from happening by setting the Tools &gt; Global Options &gt; Under Workspace changing this to Never.\nBe careful with this option because it won’t save what you don’t run.\n\n\n\n\nEvalulating Your Environment",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#calling-a-library",
    "href": "introR.html#calling-a-library",
    "title": "Introduction to R and RStudio",
    "section": "Calling a Library",
    "text": "Calling a Library\n\nIn R, a package is a collection of R functions, data and compiled code. The location where the packages are stored is called the library.\nLibraries need to be activated one time in each new R session.\nYou can access a function from a library one time using library::function()\n\n\n# Use to activate library in an R session.\nlibrary(tidyverse)\nlibrary(dplyr)\n\n\nYou can access a function from a library one time only using library::function()\n\nUseful if only using one function from the library.\n\nWe will return to this in data prep.\n\n\n## Below is an example that would use dplyr for one select function\n## to select variable1 from the oldData and save it as a new object\n## NewData. Since we don’t have datasets yet, we will revisit this.\n## NewData &lt;- dplyr::select(oldData, variable1)\n\n\nSome libraries are part of other global libraries:\n\ndplyr is part of tidyverse, there is actually no need to activate it if tidyverse is active, however, sometimes it helps when conflicts are present\nAn example of a conflict is the use of a select function which shows up in both the dplyr and MASS package. If both libraries are active, R does not know which to use.\ntidyverse has many libraries included in it.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#the-environment",
    "href": "introR.html#the-environment",
    "title": "Introduction to R and RStudio",
    "section": "The Environment",
    "text": "The Environment\n\nYou can evaluate your Environment Tab to see your Variables we have defined in R Studio.\nUse the following functions to view and remove defined variables in your Global Environment\n\n\nls()  #Lists all variables in Global Environment \n\n [1] \"A\"       \"A.A123\"  \"AB.1\"    \"B\"       \"G123AB\"  \"income\"  \"kStates\"\n [8] \"states\"  \"vote\"    \"voted\"   \"x\"       \"y\"      \n\nrm(states)  #Removes variable named states\nrm(list = ls())  #Clears all variables from Global Environment\n\n\n\n\nEvalulating Your RStudio Environment",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#entering-and-loading-data",
    "href": "introR.html#entering-and-loading-data",
    "title": "Introduction to R and RStudio",
    "section": "Entering and Loading Data",
    "text": "Entering and Loading Data\n\nCreating a Vector\n\nA vector is the simplest type of data structure in R.\n\nA vector is a set of data elements that are saved together as the same type.\nWe have many ways to create vectors with some examples below.\n\nUse c() function, which is a generic function which combines its arguments into a vector or list.\n\n\nc(1, 2, 3, 4, 5)  #Print a Vector 1:5\n\n[1] 1 2 3 4 5\n\n\n\nIf numbers are aligned, can use the “:“ symbol to include numbers and all in between. This is considered an array.\n\n\n1:5  #Print a Vector 1:5\n\n[1] 1 2 3 4 5\n\n\n\nUse seq() function to make a vector given a sequence.\n\n\nseq(from = 0, to = 30, by = 5)  #Creates a sequence vector from 0 to 30 in increments on 5 \n\n[1]  0  5 10 15 20 25 30\n\n\n\nUse rep() function to repeat the elements of a vector.\n\n\nrep(x = 1:3, times = 4)  #Repeat the elements of the vector 4 times\n\n [1] 1 2 3 1 2 3 1 2 3 1 2 3\n\nrep(x = 1:3, each = 3)  #Repeat the elements of a vector 3 times each\n\n[1] 1 1 1 2 2 2 3 3 3\n\n\n\n\nCreating a Matrix\n\nA matrix is another type of object like a vector or a list.\n\nA matrix has a rectangular format with rows and columns.\nA matrix uses matrix() function\nYou can include the byrow = argument to tell the function whether to fill across or down first.\nYou can also include the dimnames() function in addition to the matrix() to assign names to rows and columns.\n\nUsing matrix() function, we can create a matrix with 3 rows and 3 columns as shown below.\n\nTake note how the matrix fills in the new data.\n\n\n# Creating a Variable X that has 9 Values.\nx &lt;- 1:9\n# Setting the matrix.\nmatrix(x, nrow = 3, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n# Note – we do not need to name the arguments because we go in the\n# correct order.  The function below simplifies the statement and\n# provides the same answer as above.\nmatrix(x, 3, 3)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\n\n\nSetting More Arguments in a Matrix\n\nThe byrow argument fills the Matrix across the row\nBelow, we can use the byrow statement and assign it to a variable m.\n\n\nm &lt;- matrix(1:9, 3, 3, byrow = TRUE)  #Fills the Matrix Across the Row and assigns it to variable m\nm  #Printing the matrix in the console\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\n\nThe dimnames() function adds labels to either the row and the column. In this case below both are added to our matrix m.\n\n\ndimnames(x = m) &lt;- list(c(\"2020\", \"2021\", \"2022\"), c(\"low\", \"medium\", \"high\"))\nm  #Printing the matrix in the console\n\n     low medium high\n2020   1      2    3\n2021   4      5    6\n2022   7      8    9\n\n\n\nYou try to make a matrix of 25 items, or a 5 by 5, and fill the matrix across the row and assign the matrix to the name m2.\nYou should get the answer below.\n\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    2    3    4    5\n[2,]    6    7    8    9   10\n[3,]   11   12   13   14   15\n[4,]   16   17   18   19   20\n[5,]   21   22   23   24   25\n\n\n\n\nDifferences between Data Frames and Matrices\n\nIn a data frame the columns contain different types of data, but in a matrix all the elements are the same type of data. A matrix is usually numbers.\nA matrix can be looked at as a vector with additional methods or dimensions, while a data frame is a list.\n\n\n\n\nCreating a Data Frame\n\nA data frame is a table or a two-dimensional array-like structure in which each column contains values of one variable and each row contains one set of values from each column. In a data frame the rows are observations and columns are variables.\n\nData frames are generic data objects to store tabular data.\nThe column names should be non-empty.\nThe row names should be unique.\nThe data stored in a data frame can be of numeric, factor or character type.\nEach column should contain same number of data items.\nCombing vectors into a data frame using the data.frame() function\n\nBelow, we can create vectors for state, year enacted, personal oz limit medical marijuana.\n\n\nstate &lt;- c(\"Alaska\", \"Arizona\", \"Arkansas\")\nyear.legal &lt;- c(1998, 2010, 2016)\nounce.lim &lt;- c(1, 2.5, 3)\n\n\nThen, we can combine the 3 vectors into a data frame and name the data frame pot.legal.\n\n\npot.legal &lt;- data.frame(state, year.legal, ounce.lim)\n\n\nNext, check your global environment to confirm data frame was created.\n\n\n\n\nGlobal Environment\n\n\n\n\nImporting a Data Frame into R\n\nWhen importing data from outside sources, you can do the following:\n\n\nYou can import data from an R package using data() function.\nYou can also link directly to a file on the web.\nYou can import data through from your computer through common file extensions:\n\n.csv: comma separated values;\n.txt: text file;\n.xls or .xlsx: Excel file;\n.sav: SPSS file;\n.sasb7dat: SAS file;\n.xpt: SAS transfer file;\n.dta: Stata file.\n\n\n\nEach different file type requires a unique function to read in the file. With all the variety in file types, it is best to look it up in the R Community to help.\n\n\nUse data() function\n\nAll we need is the data() function to read in a data set that is part of R. R has many built in libraries now, so there are many data sets we can use for testing and learning statistics in R.\n\n\n# The mtcars data set is part of R, so no new package needs to be\n# downloaded.\ndata(\"mtcars\")\n\n\nLoad a data frame from a unique package in R.\n\nThere are also a lot of packages that house data sets. It is fairly easy to make a package that contains data and load it into CRAN. These packages need to be installed into your R one time. Then, each time you open R, you need to reload the library using the library() function.\nWhen your run the install.packages() function, do not include the # symbol. Then, after you run it one time, comment it out. There is no need to run this code a second time unless something happens to your RStudio.\n\n\n# install.packages('MASS') #only need to install package one time in\n# R\nlibrary(MASS)\n\n\n\ndata(\"Insurance\")\nhead(Insurance)\n\n  District  Group   Age Holders Claims\n1        1    &lt;1l   &lt;25     197     38\n2        1    &lt;1l 25-29     264     35\n3        1    &lt;1l 30-35     246     20\n4        1    &lt;1l   &gt;35    1680    156\n5        1 1-1.5l   &lt;25     284     63\n6        1 1-1.5l 25-29     536     84\n\n\n\n\nAccessing Variables\n\nYou can directly access a variable from a dataset using the $ symbol followed by the variable name.\nThe $ symbol facilitates data manipulation operations by allowing easy access to variables for calculations, transformations, or other analyses. For example:\n\n\nhead(Insurance$Claims)  #lists the first 6 Claims in the Insurance dataset.\n\n[1]  38  35  20 156  63  84\n\nsd(Insurance$Claims)  #provides the standard deviation of all Claims in the Insurance dataset.\n\n[1] 71.1624",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#absolute-file-paths",
    "href": "introR.html#absolute-file-paths",
    "title": "Introduction to R and RStudio",
    "section": "Absolute File Paths",
    "text": "Absolute File Paths\n\nAbsolute vs. Relative Links\nAn absolute file path provides the complete location of a file, starting from the root directory of your computer.\n\nAlways points to the same file.\nIndependent of the script’s location.\nExample: read.csv(\"C:/Users/username/Documents/data.csv\")\n\nPro\n\nReliable for your system\nNo Ambiguity in locating files\n\nCons\n\nNot portable; requires the same file structure across systems.\nHarder to share code with collaborators.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#relative-file-paths",
    "href": "introR.html#relative-file-paths",
    "title": "Introduction to R and RStudio",
    "section": "Relative File Paths",
    "text": "Relative File Paths\n\nA relative file path specifies the file location based on the working directory of your R project or script.\n\nChanges based on the working directory.\nOften starts from the project folder.\nExample: read.csv(\"data/myfile.csv\")\n\nPros\n\nMore portable; works across systems if the project structure is consistent.\nEasier collaboration when sharing code and project files.\n\nCons\n\nRequires setting the working directory correctly (getwd() and setwd() can help).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#setting-up-a-working-directory",
    "href": "introR.html#setting-up-a-working-directory",
    "title": "Introduction to R and RStudio",
    "section": "Setting up a Working Directory",
    "text": "Setting up a Working Directory\n\nYou should have the data files from our LMS in a data folder on your computer. Your project folder would contain that data folder.\nBefore importing and manipulating data, you must find and edit your working directory to directly connect to your project folder!\nThese functions are good to put at the top of your R files if you have many projects going at the same time.\n\n\ngetwd()  #Alerts you to what folder you are currently set to as your working directory\n# For example, my working directory is set to the following:\n# setwd('C:/Users/Desktop/ProbStat') #Allows you to reset the working\n# directory to something of your choice.\n\n\nIn R, when using the setwd() function, notice the forward slashes instead of backslashes.\nYou can also go to Tools &gt; Global Options &gt; General and reset your default working directory when not in a project. This will pre-select your working directory when you start R.\nOr if in a project, like we should be, you can click the More tab as shown in the Figure below, and set your project folder as your working directory.\n\n\n\n\nSetting Your Working Directory\n\n\n##Reading in Data from .csv\n\nReading in a .csv file is extremely popular way to read in data.\nThere are a few functions to read in .csv files. And these functions would change based on the file type you are importing.\n\n\nread.csv() function\n\nExtremely popular way to read in data.\nread.csv() is a base R function that comes built-in with R: No library necessary\nAll your datasets should be in a data folder in your working directory so that you and I have the same working directory. This creates a relative path to our working directory.\nThe structure of the function is datasetName &lt;- read.csv(“data/dataset.csv”).\n\n\ngss.2016 &lt;- read.csv(file = \"data/gss2016.csv\")\n# or equivalently\ngss.2016 &lt;- read.csv(\"data/gss2016.csv\")\n# Examine the contents of the file\nsummary(object = gss.2016)\n\n    grass               age           \n Length:2867        Length:2867       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\n# Or equivalently, we can shorten this to the following code\nsummary(gss.2016)\n\n    grass               age           \n Length:2867        Length:2867       \n Class :character   Class :character  \n Mode  :character   Mode  :character",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "introR.html#read_csv-function",
    "href": "introR.html#read_csv-function",
    "title": "Introduction to R and RStudio",
    "section": "read_csv function",
    "text": "read_csv function\n\nread_csv() is a function from the readr package, which is part of the tidyverse ecosystem.\nread_csv() is generally faster than read.csv() as it’s optimized for speed, making it more efficient, particularly for large datasets.\nIn R, both read.csv() and read_csv() are used to read CSV files, but they come from different packages and have important differences. read.csv() is part of base R and is widely used for loading CSV files into data frames, as in data &lt;- read.csv(\"data/data.csv\"). It can be slower with large datasets and automatically converts strings to factors unless stringsAsFactors = FALSE.\nread_csv(), from the readr package in the tidyverse, is faster and better suited for large datasets. You’d use it like data &lt;- readr::read_csv(\"data/data.csv\"). It doesn’t convert strings to factors by default and provides clearer error messages.read_csv() is often preferred for performance and better handling of data types, especially in larger datasets or tidyverse projects.\n\n\n# install.packages(tidyverse) ## Only need to install one time on\n# your computer. #install.packages links have been commented out\n# during processing of RMarkdown.  Activate the library, which you\n# need to access each time you open R and RStudio\nlibrary(tidyverse)\n\n\n# Now open the data file to evaluate with tidyverse\ngss.2016b &lt;- read_csv(file = \"data/gss2016.csv\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "descriptives.html",
    "href": "descriptives.html",
    "title": "Descriptive Statistics",
    "section": "",
    "text": "Lesson Objectives",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives.html#summarizing-qualitative-data",
    "href": "descriptives.html#summarizing-qualitative-data",
    "title": "Descriptive Statistics",
    "section": "Summarizing Qualitative Data",
    "text": "Summarizing Qualitative Data\n\nQualitative data is information that cannot be easily counted, measured, or easily expressed using numbers.\n\nNominal variables: a type of categorical variable that represents discrete categories or groups with no inherent order or ranking\n\ngender (male, female)\nmarital status (single, married, divorced)\neye color (blue, brown, green)\n\nOrdinal variables: categories possess a natural order or ranking\n\na Likert scale measuring agreement with a statement (e.g., strongly disagree, disagree, neutral, agree, strongly agree)\n\n\nA frequency distribution shows the number of observations in each category for a factor or categorical variable.\nGuidelines when constructing frequency distribution:\n\nClasses or categories are mutually exclusive (they are all unique).\nClasses or categories are exhaustive (a full list of categories).\n\nTo calculate frequencies, first, start with a variable that has categorical data.\n\n\n# Create a vector with some data that could be categorical\nSample_Vector &lt;- c(\"A\", \"B\", \"A\", \"C\", \"A\", \"B\", \"A\", \"C\", \"A\", \"B\")\n# Create a data frame with the vector\ndata &lt;- data.frame(Sample_Vector)\n\n\nTo count the number of each category value, we can use the table() command.\nThe output shows a top row of categories and a bottom row that contains the number of observations in the category.\n\n\n# Create a table of frequencies\nfrequencies &lt;- table(data$Sample_Vector)\nfrequencies\n\n\nA B C \n5 3 2 \n\n\n\nRelative frequency is how often something happens divided by all outcomes.\nThe relative frequency is calculated by \\(f_i/n\\), where \\(f_i\\) is the frequency of class \\(i\\) and \\(n\\) is the total frequency.\nWe can use the prop.table() command to calculate relative frequency by dividing each category’s frequency by the sample size.\n\n\n# Calculate proportions\nproportions &lt;- prop.table(frequencies)\n\n\nThe cumulative relative frequency is given by \\(cf_i/n\\), where \\(cf_i\\) is the cumulative frequency of class \\(i\\).\nThe cumsum() function calculates the cumulative distribution of the data\n\n\n# Calculate cumulative frequencies\ncumulfreq &lt;- cumsum(frequencies)\n# Calculate cumulative proportions\ncumulproportions &lt;- cumsum(prop.table(frequencies))\n\n\nThe rbind() function is used to combine multiple data frames or matrices by row. The name “rbind” stands for “row bind”. Since the data produced by the table is in rows, we can use rbind to link them together.\n\n\n# combine into table\nfrequency_table &lt;- rbind(frequencies, proportions, cumulfreq, cumulproportions)\n# Print the table\nfrequency_table\n\n                   A   B    C\nfrequencies      5.0 3.0  2.0\nproportions      0.5 0.3  0.2\ncumulfreq        5.0 8.0 10.0\ncumulproportions 0.5 0.8  1.0\n\n\n\nWe can transpose a table using the t() command, which flips the dataset.\n\n\nTransposedData &lt;- t(frequency_table)\nTransposedData\n\n  frequencies proportions cumulfreq cumulproportions\nA           5         0.5         5              0.5\nB           3         0.3         8              0.8\nC           2         0.2        10              1.0\n\n\n\nFinally, sometimes we need to transform our calculations into a dataset.\nThe as.data.frame function is used to coerce or convert an object into a data frame.\nas.data.frame() is used when you have an existing object that needs to be coerced into a data frame. data.frame(), on the other hand, is for creating a data frame from scratch by specifying the data directly. Therefore, both as.data.frame() and data.frame() are used to convert or create data frames in R.\nas.data.frame() coerces an existing object (such as a list, matrix, or vector) into a data frame. Data.frame is used to create a new data frame from individual vectors or lists.\nas.data.frame() accepts a wider variety of inputs (like lists, matrices, and vectors), while data.frame() directly accepts vectors and lists to construct the data frame.\n\n\nTransposedData &lt;- as.data.frame(TransposedData)\nTransposedData\n\n  frequencies proportions cumulfreq cumulproportions\nA           5         0.5         5              0.5\nB           3         0.3         8              0.8\nC           2         0.2        10              1.0",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives.html#summarizing-quantitative-data",
    "href": "descriptives.html#summarizing-quantitative-data",
    "title": "Descriptive Statistics",
    "section": "Summarizing Quantitative Data",
    "text": "Summarizing Quantitative Data\n\nDefining and Calculating Central Tendency\n\nThe term central location refers to how numerical data tend to cluster around some middle or central value.\nMeasures of central location attempt to find a typical or central value that describes a variable.\nWhy frequency distributions do not work for numeric variables:\n\nNumeric variables measured on a continuum.\nInstead, we calculate descriptive statistics including central tendency and spread of the values for a numeric variable.\n\nWe will examine the three mostly widely used measures of central location: mean, median and mode.\nThen we discuss a percentile: a measure of relative position.\n\n\nUsing the Mean\n\nThe arithmetic mean or simply the mean is a primary measure of central location. It is often referred to as the average. Simply add up all the observations and divide by the number of observations.\nThe numerator (top of the fraction) is the sum (sigma) of all the values of x from the first value (i = 1) to the last value (n) divided by the number of values (n).\n\\(m_x = (\\sum_{i=1}^{n} x_{i})/n\\)\nConsider the salaries of employees at a company: \nWe can use the mean() command to calculate the mean in R.\n\n\n# Create Vector of Salaries\nsalaries &lt;- c(40000, 40000, 65000, 90000, 145000, 150000, 550000)\n# Calculate the mean using the mean() command\nmean(salaries)\n\n[1] 154285.7\n\n\n\nNote that due to at least one outlier this mean does not reflect the typical salary - more on that later.\nIf we edit our vector to include NAs, we have to account for this. This is a common way to handle NAs in functions that do not allow for them.\n\n\nsalaries2 &lt;- c(40000, 40000, 65000, 90000, 145000, 150000, 550000, NA,\n    NA)\n# Calculate the mean using the mean() command Notice that it does not\n# work\nmean(salaries2)\n\n[1] NA\n\n# Add in na.rm parameter to get it to produce the mean with no NAs.\nmean(salaries2, na.rm = TRUE)\n\n[1] 154285.7\n\n\n\nNote that there are other types of means like the weighted mean or the geometric mean.\n\nThe weighted mean uses weights to determine the importance of each data point of a variable. It is calculated by \\(\\bar{x}_w = \\frac{\\sum_{i=1}^{n} w_i x_i}{\\sum_{i=1}^{n} w_i}\\), where are the weights associated to the values.\nAn example is below.\n\n\nvalues &lt;- c(4, 7, 10, 5, 6)\nweights &lt;- c(1, 2, 3, 4, 5)\nweighted_mean &lt;- weighted.mean(values, weights)\nweighted_mean\n\n[1] 6.533333\n\n\n\n\nUsing the Median\n\nThe median is another measure of central location that is not affected by outliers.\nWhen the data are arranged in ascending order, the median is:\n\nThe middle value if the number of observations is odd, or\nThe average of the two middle values if the number of observations is even.\n\nConsider the sorted salaries of employees presented earlier which contains an odd number of observations.\n\nOn the same salaries vector created above, use median() command to calculate the median in R.\n\n\n# Calculate the median using the median() command\nmedian(salaries)\n\n[1] 90000\n\n\n\nNow compare to the mean and note the large difference in numbers signifying that at least one outlier is most likely present.\nSpecifically, if the mean and median are different, it is likely the variable is skewed and contains outliers.\n\n\nmean(salaries)\n\n[1] 154285.7\n\n\n\nFor another example, consider the sorted data below that contains an even number of values.\n\n\nGrowthFund &lt;- c(-38.32, 1.71, 3.17, 5.99, 12.56, 13.47, 16.89, 16.96, 32.16,\n    36.29)\n\n\nWhen data contains an even number of values, the median is the average of the 2 sorted middle numbers (12.56 and 13.47).\n\n\nmedian(GrowthFund)\n\n[1] 13.015\n\n(12.56 + 13.47)/2\n\n[1] 13.015\n\n# The mean is still the average\nmean(GrowthFund)\n\n[1] 10.088\n\n\n\n\nUsing the Mode\n\nThe mode is another measure of central location.\nThe mode is the most frequently occurring value in a data set.\nThe mode is useful in summarizing categorical data but can also be used to summarize quantitative data.\nA data set can have no mode, one mode (unimodal), two modes (bimodal) or many modes (multimodal).\nThe mode is less useful when there are more than three modes.\n\n\n\nExample of Function with Salary Variable\n\nWhile this is a small vector, when working with a large dataset and a function like sort(x = table(salaries), decreasing = TRUE), appending [1:5] is a way to focus on the top results after the frequencies have been computed and sorted. Specifically, table(salaries) calculates the frequency of each unique salary, sort(…, decreasing = TRUE) orders these frequencies from highest to lowest, and [1:5] selects the first five entries in the sorted list. This is useful when the dataset contains many unique values, as it allows you to quickly identify and extract the top 5 most frequent salaries, providing a concise summary without being overwhelmed by the full distribution.\nConsider the salary of employees presented earlier. 40,000 appears 2 times and is the mode because that occurs most often.\n\n\n# Try this command with and without it.\nsort(x = table(salaries), decreasing = TRUE)[1:5]\n\nsalaries\n 40000  65000  90000 145000 150000 \n     2      1      1      1      1 \n\n\n\n\nFinding No Mode\n\nLook at the sort(table()) commands with the GrowthFund Vector we made earlier.\nI added a 1:5 in square brackets at the end of the statement to produce the 3 highest frequencies found in the vector.\n\n\nsort(table(GrowthFund), decreasing = TRUE)[1:5]\n\nGrowthFund\n-38.32   1.71   3.17   5.99  12.56 \n     1      1      1      1      1 \n\n\n\nEven if you use this command, you still need to evaluate the data more systematically to verify the mode. If the highest frequency of the sorted table is 1, then there is no mode.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives.html#defining-and-calculating-spread",
    "href": "descriptives.html#defining-and-calculating-spread",
    "title": "Descriptive Statistics",
    "section": "Defining and Calculating Spread",
    "text": "Defining and Calculating Spread\n\nSpread is a measure of distance values are from the central value.\nEach measure of central tendency has one or more corresponding measures of spread.\nMean: use variance or standard deviation to measure spread.\n\nskewness and kurtosis help measure spread as well.\n\nMedian: use range or interquartile range (IQR) to measure spread.\nMode: use the index of qualitative variation to measure spread.\n\nNot formally testing here with a function.\n\n\n\nSpread to Report with the Mean\n\nEvaluating Skewness\n\nSkewness is a measure of the extent to which a distribution is skewed.\nCan evaluate skewness visually with histogram.\n\nA histogram is a visual representation of a frequency or a relative frequency distribution.\nBar height represents the respective class frequency (or relative frequency).\nBar width represents the class width.\n\n\n\n\n\nEvaluating Skewness Visually\n\n\n\n\nSkewed Distributions: Median Not Same as Mean\n\nSometimes, a histogram is difficult to tell if skewness is present or if the data is relatively normal or symmetric.\nIf Mean is less than Median and Mode, then the variable is Left-Skewed.\nIf the Mean is greater than the Median and Mode, then the variable is Right-Skewed.\nIf the Mean is about equal to the Median and Mode, then the variable has a symmetric distribution.\nIn R, we can easily look at mean and median with the summary() command.\n\n\n\n\nEvaluating Skewness Using Mean and Median\n\n\n\nMean is great when data are normally distributed (data is not skewed).\nMean is not a good representation of skewed data where outliers are present.\n\nAdding together a set of values that includes a few very large or very small values like those on the far left of a left-skewed distribution or the far right of the right-skewed distribution will result in a large or small total value in the numerator of Equation and therefore the mean will be a large or small value relative to the actual middle of the data.\n\n\n\n\nUsing skew() Command in R\n\nThe skew() command is from the semTools package. The install.packages() command is commented out below, but install it one time on your R before commenting it out.\n\n\n# install the semTools package if necessary.\n# install.packages('semTools') Activate the library\nlibrary(semTools)\n\n\nAfter the package is installed and loaded, run the skew() command on the salaries vector made above.\n\n\nskew(salaries)\n\nskew (g1)        se         z         p \n    2.311     0.926     2.496     0.013 \n\n\n\n\nInterpreting the skew() Command Results\n\nse = standard error\nz = skew/se\nIf the sample size is small (n &lt; 50), z values outside the –2 to 2 range are a problem.\nIf the sample size is between 50 and 300, z values outside the –3.29 to 3.29 range are a problem.\nFor large samples (n &gt; 300), using a visual is recommended over the statistics, but generally z values outside the range of –7 to 7 can be considered problematic.\nSalary: Our sample size was small, &lt;50, so the z value of 2.496 in regards to the salary vector indicates there is a problem with skewness.\nGrowthFund: We can check the skew of GrowthFund.\n\n\nskew(GrowthFund)\n\nskew (g1)        se         z         p \n   -1.381     0.775    -1.783     0.075 \n\n\n\nGrowthFund was also considered a small sample size, so the same -2/2 thresholds are used. Here, our z value is -1.78250137, which is in normal range. This indicates there is no problem with skewness.\n\n\n\n\nHistograms\n\nA histogram is a graphical representation of the distribution of numerical data.\nIt consists of a series of contiguous rectangles, or bars, where the area of each bar corresponds to the frequency of observations within a particular range or bin of values.\nThe x-axis typically represents the range of values being measured, while the y-axis represents the frequency or count of observations falling within each range.\nHistograms are commonly used in statistics and data analysis to visualize the distribution of a dataset and identify patterns or trends.\nThey are particularly useful for understanding the central tendency, variability, and shape of the data distribution - this includes our observation of skewness.\nWorks much better with larger datsets.\n\n\nCommands to Make a Histogram\n\nhist() command in base R.\ngeom_histogram() command in ggplot2 package.\na hist using the GrowthFund dataset does not look that great because its sample size is so small.\n\n\nhist(GrowthFund)\n\n\n\n\n\n\n\n\n\n\nhist vs geom_histogram\n\nIn R, hist() and geom_histogram() are both used to create histograms, but they belong to different packages and have slightly different functionalities.\n\n\n# Making an appropriate data.frame to use the hist() command\nHousePrice &lt;- c(430, 520, 460, 475, 670, 521, 670, 417, 533, 525, 538,\n    370, 530, 525, 430, 330, 575, 555, 521, 350, 399, 560, 440, 425, 669,\n    660, 702, 540, 460, 588, 445, 412, 735, 537, 630, 430)\nHousePrice &lt;- data.frame(HousePrice)\n\n\nhist(): This function is from the base R graphics package and is used to create histograms. It provides a simple way to visualize the distribution of a single variable.\n\n\n# Using base R to create the histogram.\nhist(HousePrice$HousePrice, breaks = 5, main = \"A Histogram\", xlab = \"House Prices (in $1,000s)\",\n    col = \"yellow\")\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\ngeom_histogram(): This function is from the ggplot2 package, which is part of the tidyverse. It is used to create histograms as part of a more flexible and powerful plotting system.\n\n\n# Using geom_histogram() command to create the histogram.\nggplot(HousePrice, aes(x = HousePrice)) + geom_histogram(binwidth = 100,\n    boundary = 300, color = \"black\", fill = \"yellow\") + labs(title = \"A Histogram\",\n    x = \"House Prices (in $1,000s)\", y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nWe could add more parameters here to make the 2 histograms look identical, but this configuration of parameters is very close. Take note that there are a lot more parameters you can add to the geom_histogram() command than you can with base R to make it look more professional. Be sure to look them up and also check with the notes in the book, which focuses on geom_histogram instead of hist().\nVariance is a measure of spread for numeric variables that is essentially the average of the squared differences between each observation value on some variable and the mean for that variable with population variance. \\[Population Var(X) = \\sigma^2 = \\sum{(x_i-\\mu)^2}/N\\] \\[Sample Var(x) = s^2 = \\sum{(x_i-\\bar{x})^2}/(n-1)\\]\nStandard deviation is the square root of the variance.\n\nUse var() command and sd() command to calculate sample variance and sample standard deviation.\n\n\n\n## Calculated from Small Sample\nx &lt;- c(1, 2, 3, 4, 5)\nsum((x - mean(x))^2/(5 - 1))\n\n[1] 2.5\n\nvar(x)\n\n[1] 2.5\n\nsqrt(var(x))\n\n[1] 1.581139\n\nsd(x)\n\n[1] 1.581139\n\nsd(HousePrice$HousePrice)  #102.6059\n\n[1] 102.6059\n\nvar(HousePrice$HousePrice)  #10527.97\n\n[1] 10527.97\n\nskew(HousePrice$HousePrice)  #normal\n\nskew (g1)        se         z         p \n    0.317     0.408     0.777     0.437 \n\n\nLooking at Spread for a Larger Dataset\n\n\ncustomers &lt;- read.csv(\"data/customers.csv\")\nsummary(customers$Spending, na.rm = TRUE)  #mean and median\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   50.0   383.8   662.0   659.6   962.2  1250.0 \n\nmean(customers$Spending, na.rm = TRUE)  #mean by itself\n\n[1] 659.555\n\nmedian(customers$Spending, na.rm = TRUE)  #median by itself\n\n[1] 662\n\n### Spread to Report with the Mean\nsd(customers$Spending, na.rm = TRUE)\n\n[1] 350.2876\n\nvar(customers$Spending, na.rm = TRUE)\n\n[1] 122701.4\n\n\n\n\nKurtosis in Evaluating Mean Spread\n\nKurtosis is the sharpness of the peak of a frequency-distribution curve or more formally a measure of how many observations are in the tails of a distribution.\nThe formula for kurtosis is as follows: Kurtosis = \\(\\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum \\left( \\frac{(X_i - \\bar{X})^4}{s^4} \\right) - \\frac{3(n-1)^2}{(n-2)(n-3)}\\)\n\nWhere:\n\n\\(n\\) is the sample size\n\\(X_i\\) is each individual value\n\\(\\bar{X}\\) is the mean of the data\n\\(s\\) is the standard deviation\nA normal distribution will have a kurtosis value of three, where distributions with kurtosis around 3 are described as mesokurtic, significantly higher than 3 indicate leptokurtic, and significantly under 3 indicate platykurtic.\nThe kurtosis() command from the semTools package subtracts 3 from the kurtosis, so we can evaluate values by comparing them to 0. Positive values will be indicative to a leptokurtic distribution and negative will indicate a platykurtic distribution. To see if kurtosis (leptokurtic or platykurtic) is significant, we confirm them by first evaluating the z-score to see if the variable is normal or not. The same cutoff values from skew also apply for the z for small, medium, and large sample sizes in kurtosis. These are the same basic rules for the rules in judging skewness.\n\n\n\n\nEvaluate Kurtosis\n\n\n\nThe rules of determining problematic distributions with regards to kurtosis are below.\n\nIf the sample size is small (n &lt; 50), z values outside the –2 to 2 range are a problem.\nIf the sample size is between 50 and 300, z values outside the –3.29 to 3.29 range are a problem.\nFor large samples (n &gt; 300), using a visual is recommended over the statistics, but generally z values outside the range of –7 to 7 can be considered problematic.\nIf kurtosis is found, then evaluate the excess kur score to see if it is positive or negative to determine whether it is leptokurtic or platykurtic.\n\n\n\n# z-value is 3.0398, which is &gt; 2 indicating leptokurtic Small sample\n# size: range is -2 to 2\nkurtosis(salaries)\n\nExcess Kur (g2)              se               z               p \n          5.629           1.852           3.040           0.002 \n\n# z-value is 2.20528007, which is &gt; 2 indicating leptokurtic Small\n# sample size: range is -2 to 2\nkurtosis(GrowthFund)\n\nExcess Kur (g2)              se               z               p \n          3.416           1.549           2.205           0.027 \n\n# Small sample size: range is -2 to 2 Skewness and kurtosis are both\n# in range.\nskew(HousePrice$HousePrice)  #normal\n\nskew (g1)        se         z         p \n    0.317     0.408     0.777     0.437 \n\nkurtosis(HousePrice$HousePrice)  #normal\n\nExcess Kur (g2)              se               z               p \n         -0.540           0.816          -0.661           0.508 \n\n\n\nLet’s do a few more examples using the customers dataset.\n\n\n# Noted sample size at 200 observations or a medium sample size.\n# Using threshold –3.29 to 3.29 to assess normality.\n\n#-3.4245446445 is below -3.29 so kurtosis is present\n# Negative kurtosis value indicates platykurtic\nkurtosis(customers$Spending)\n\nExcess Kur (g2)              se               z               p \n         -1.186           0.346          -3.425           0.001 \n\ngeom_histogram(binwidth = 100, fill = \"pink\", color = \"black\")\n\ngeom_bar: na.rm = FALSE, orientation = NA\nstat_bin: binwidth = 100, bins = NULL, na.rm = FALSE, orientation = NA, pad = FALSE\nposition_stack \n\nsemTools::skew(customers$Spending)  ##normal indicating no skewness\n\nskew (g1)        se         z         p \n   -0.018     0.173    -0.106     0.916 \n\n# Normal: 2.977622119 is in between -3.29 and 3.29\nkurtosis(customers$Income)\n\nExcess Kur (g2)              se               z               p \n          1.031           0.346           2.978           0.003 \n\nggplot(customers, aes(Income)) + geom_histogram(binwidth = 10000, fill = \"pink\",\n    color = \"black\")\n\n\n\n\n\n\n\nsemTools::skew(customers$Income)  #Skewed right\n\nskew (g1)        se         z         p \n    0.874     0.173     5.047     0.000 \n\n#-3.7251961028 is below -3.29 so kurtosis is present\n# Negative kurtosis value indicates platykurtic\nkurtosis(customers$HHSize)\n\nExcess Kur (g2)              se               z               p \n         -1.290           0.346          -3.725           0.000 \n\nggplot(customers, aes(HHSize)) + geom_histogram(binwidth = 1, fill = \"pink\",\n    color = \"black\")\n\n\n\n\n\n\n\nsemTools::skew(customers$HHSize)  #normal\n\nskew (g1)        se         z         p \n   -0.089     0.173    -0.513     0.608 \n\n# Normal: -0.20056607 is in between -3.29 and 3.29\nkurtosis(customers$Orders)\n\nExcess Kur (g2)              se               z               p \n         -0.069           0.346          -0.201           0.841 \n\ngeom_histogram(binwidth = 5, fill = \"pink\", color = \"black\")\n\ngeom_bar: na.rm = FALSE, orientation = NA\nstat_bin: binwidth = 5, bins = NULL, na.rm = FALSE, orientation = NA, pad = FALSE\nposition_stack \n\nsemTools::skew(customers$Orders)  ##skewed right\n\nskew (g1)        se         z         p \n    0.789     0.173     4.553     0.000 \n\n\n\n\n\nSpread to Report with the Median\n\nRange = Maximum Value – Minimum Value.\n\nSimplest measure.\nFocuses on Extreme values.\nUse commands diff(range()) or max() – min().\n\nIQR: Difference between the first and third quartiles.\n\nUse IQR() command or quantile() command.\n\n\nsummary(customers$Spending, na.rm = TRUE)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   50.0   383.8   662.0   659.6   962.2  1250.0 \n\ndiff(range(customers$Spending, na.rm = TRUE))\n\n[1] 1200\n\nmax(customers$Spending, na.rm = TRUE) - min(customers$Spending, na.rm = TRUE)\n\n[1] 1200\n\nIQR(customers$Spending, na.rm = TRUE)\n\n[1] 578.5\n\n\n\n\n\nSpread to Report with the Mode\n\nWhile there is no great function to test for spread, you can look at the data and see if it is concentrated around 1 or 2 frequencies. If it is, then the spread is distorted towards those high frequency values.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives.html#using-ai",
    "href": "descriptives.html#using-ai",
    "title": "Descriptive Statistics",
    "section": "Using AI",
    "text": "Using AI\nUse the following prompts on a generative AI, like chatGPT, to learn more about descriptive statistics.\n\nWhat is the difference between mean, median, and mode in describing data distributions, and how can each be used to understand the shape of a distribution? * How do mean and median help identify whether a distribution is skewed, and what does it tell us about the dataset?\nCan you explain how the mean, median, and mode behave in normal, positively skewed, and negatively skewed distributions?\nWhat are standard deviation (SD) and variance, and how do they measure the spread of data in a distribution?\nExplain the differences between range, interquartile range (IQR), and standard deviation in describing the variability in a dataset.\nHow does a high standard deviation or variance affect the interpretation of a dataset compared to a low standard deviation?\nWhat is skewness, and how does it affect the shape of a distribution? How can we identify positive and negative skew?\nHow is kurtosis defined in the semTools package in R, and what does it tell us about the tails of a distribution?\nHow would you compare and contrast the roles of skewness and kurtosis in identifying the shape and behavior of a distribution?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives.html#summary",
    "href": "descriptives.html#summary",
    "title": "Descriptive Statistics",
    "section": "Summary",
    "text": "Summary\n\nIn this lesson, we worked through descriptive statistics including skewness and kurtosis. We learned about variables and scales of measurement, how to summarize qualitative and quantitative data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  }
]